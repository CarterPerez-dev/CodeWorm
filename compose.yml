# Â©AngelaMos | 2026
# compose.yml
# =============================================================================
# Production compose - Nginx + Dashboard + Ollama + Redis
# CodeWorm daemon runs on host via systemd, not in Docker
# =============================================================================

name: ${APP_NAME:-codeworm}

services:
  nginx:
    build:
      context: .
      dockerfile: infra/docker/frontend-builder.prod
      args:
        - VITE_API_URL=${VITE_API_URL:-/api}
        - VITE_APP_TITLE=${VITE_APP_TITLE:-CodeWorm Dashboard}
    container_name: ${APP_NAME:-codeworm}-nginx
    ports:
      - "${NGINX_HOST_PORT:-38491}:80"
    depends_on:
      dashboard:
        condition: service_healthy
    networks:
      - frontend
      - backend
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 64M
    restart: unless-stopped

  dashboard:
    build:
      context: .
      dockerfile: infra/docker/dashboard.prod
    container_name: ${APP_NAME:-codeworm}-dashboard
    ports:
      - "${DASHBOARD_HOST_PORT:-53172}:8000"
    expose:
      - "8000"
    env_file:
      - .env
    environment:
      - ENVIRONMENT=production
      - DEBUG=false
      - REDIS_URL=redis://redis:6379
      - CODEWORM_DB_PATH=/data/codeworm.db
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ./data:/data:ro
    networks:
      - backend
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 256M
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 40s
    restart: unless-stopped

  ollama:
    image: ollama/ollama:latest
    container_name: ${APP_NAME:-codeworm}-ollama
    ports:
      - "${OLLAMA_HOST_PORT:-47311}:11434"
    volumes:
      - ollama_data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:11434/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    container_name: ${APP_NAME:-codeworm}-redis
    ports:
      - "${REDIS_HOST_PORT:-26849}:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    networks:
      - backend
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

networks:
  frontend:
    driver: bridge
  backend:
    driver: bridge

volumes:
  ollama_data:
  redis_data:
